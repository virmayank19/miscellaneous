import numpy as np
from sentence_transformers import SentenceTransformer
from annoy import AnnoyIndex
from data_definitions import data

# Create text embeddings
model = SentenceTransformer('all-mpnet-base-v2')  # Choose a suitable model
embeddings = model.encode(list(data.values()))

# Build vector index
f = 768  # Dimensionality of the embeddings from the 'all-mpnet-base-v2' model
t = AnnoyIndex(f, 'angular')  # Use angular distance for text similarity
for i, embedding in enumerate(embeddings):
    t.add_item(i, embedding)
t.build(10)  # Adjust the number of trees for performance

def vector_search(query, top_k=5):
    query_embedding = model.encode([query])[0]
    nns = t.get_nns_by_vector(query_embedding, top_k, include_distances=True)
    
    results = []
    for idx, distance in zip(nns[0], nns[1]):
        field_name = list(data.keys())[idx]
        results.append((field_name, distance))
    
    return results

# Example usage
query = "location"
results = vector_search(query, top_k=5)
print("Top 5 matching results for '{}':".format(query))
for result in results:
    print(result[0], " - Distance:", result[1])

query = "currency"
results = vector_search(query, top_k=5)
print("\nTop 5 matching results for '{}':".format(query))
for result in results:
    print(result[0], " - Distance:", result[1])





import spacy

# Load the pre-trained word embeddings model from spaCy
nlp = spacy.load("en_core_web_md")

# Sample data with field names and descriptions
data = {
    "FieldName": "description",
    "SourceName": "name of the Source system",
    "L8n": "trading location of the Source system",
    "Currency": "Currency in which the amount of the position is denoted."
}

# Function to get the most relevant field based on user input
def vector_search(user_input):
    # Calculate the similarity between user input and each field description
    similarities = {field: nlp(user_input).similarity(nlp(description)) for field, description in data.items()}
    
    # Get the field with the highest similarity
    most_relevant_field = max(similarities, key=similarities.get)
    
    return most_relevant_field

# Example usage
user_input = input("Enter your query: ")
result = vector_search(user_input)

print(f"The most relevant field for '{user_input}' is: {result}")
